import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from math import pi
import requests
import json
from streamlit_extras.let_it_rain import rain
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tfidf_novelty import get_tfidf_novelty
from commercial import get_top_5_tfidf, get_business_status_distribution, get_percentile_by_category, generate_commercial_analysis
from parallel_summary import chat_with_openai, process_inputs_in_parallel, processed_results_to_df
from io import StringIO

import groq
import re
import time

# Initialize session state variables
if 'api_response' not in st.session_state:
    st.session_state.api_response = None
if 'display_commercial_analysis' not in st.session_state:
    st.session_state.display_commercial_analysis = False
# if 'selected_idea_index' not in st.session_state:
#     st.session_state.selected_idea_index = None


# testing with mock json data to save money
with open('mock_data.json', 'r') as file:
    mock_json = json.load(file)

# loading system prompt to make the code cooler
with open('system_prompt.txt', 'r') as file:
    system_prompt = file.read()

# Read the file contents for economical analysis
documents = pd.read_csv('Cleaned_ValidationSet.csv', encoding='ISO-8859-1')

# Sidebar for a cute earth icon and for loading user's api key
with st.sidebar:
    st.image("earth.png", width=250)
    # For example, links or additional instructions
 #   api_key = 
 # st.text_input("Enter your API key", type="password")
 #   st.write("We require a GPT-4 Turbo API key, specifically the model gpt-4-1106-preview. Please note that usage may incur charges.")
 #  st.markdown("_(**Please review your API key agreement to understand privacy implications before using our evaluator.**)_", unsafe_allow_html=True)

def emoji():
    rain(
        emoji="üåè",
        font_size=30,
        falling_speed=10,
        animation_length="infinite",
    )

# for fun, but we commented it out
# emoji()

# @st.cache(allow_output_mutation=True)
# def cached_processed_results_to_df(processed_results):
#     return processed_results_to_df(processed_results)

def convert_df_to_csv(df):
    output = StringIO()
    df.to_csv(output, index=False)  # index=False to not include row indices
    return output.getvalue()

# st.title('üåè Earth Hack')

# metrics list for sustainability evaluation
metrics = [
    "1_No_Poverty", "2_Zero_Hunger", "3_Good_Health_and_Well-being",
    "4_Quality_Education", "5_Gender_Equality", "6_Clean_Water_and_Sanitation",
    "7_Affordable_and_Clean_Energy", "8_Decent_Work_and_Economic_Growth",
    "9_Industry_Innovation_and_Infrastructure", "10_Reduced_Inequality",
    "11_Sustainable_Cities_and_Communities", "12_Responsible_Consumption_and_Production",
    "13_Climate_Action", "14_Life_Below_Water", "15_Life_on_Land",
    "16_Peace_Justice_and_Strong_Institutions", "17_Partnerships_for_the_Goals"
]

# variable to temporarely store api response
temp_response = ""

def format_metric_name(metric):
    # Split the string at the underscore and return the part after it
    return metric.split('_', 1)[1].replace('_', ' ')

formatted_metrics = [format_metric_name(metric) for metric in metrics]

# Emoji function based on score for table
def score_to_emoji(score):
    if score <= 4:
        return "üî¥"  # Red circle for low scores
    elif 5 <= score <= 6:
        return "üü°"  # Yellow circle for medium scores
    else:
        return "üü¢"  # Green circle for high scores


# Function to call GPT API and process the response
def evaluate_idea(problem, solution):
    # return mock_json

    # Pass the apikey to the OpenAI library
    groq.api_key = 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

    # try:
    response = groq.ChatCompletion.create(
     #   model="gpt-4-1106-preview",
        messages=[{"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Problem:{problem}\n\nSolution:{solution}"}
            ],
        max_tokens= 4096,#128000,
    )
        
    response = response["choices"][0]["message"]["content"]
    # ai_response = re.sub(r'^```json\n\n|\n```$', '', response)
    
    ai_response = re.sub(r'`|json', '', response)
    
    # st.markdown("## OUTPUT 0 Response:")
    # st.write(ai_response)
                
    output = json.loads(ai_response)
        
        # st.markdown("## OUTPUT 1 Response:")
        # st.markdown(output)
    
    return output
    

### pretty interface for user prompt

st.title("üí° Sustainability Idea Evaluation")

# App Introduction
with st.expander("Introduction of Our App", expanded=True):
    st.write("""
        This Streamlit application is designed to evaluate business ideas based on a problem-solution approach, with a focus on assessing their sustainability. It generates scores for novelty and sustainability aspects of the idea, helping users understand the potential impact and uniqueness of their business concepts.
    """)

# Option for user to choose input method
input_method = st.radio("Choose your input method:", ('Manual Input', 'Upload CSV'))

# Placeholder text for 'Problem' and 'Solution' inputs
problem_placeholder = "More than 130 billion plastic bottles waste annually in Egypt"
solution_placeholder = "Bariq factory to recycle plastic bottles"

        
if input_method == 'Manual Input':
    with st.form("business_idea_form"):
        problem = st.text_area("Problem:", value="", placeholder=problem_placeholder)
        solution = st.text_area("Solution:", value="", placeholder=solution_placeholder)
        submit_button = st.form_submit_button("Evaluate Idea")
    

    # if sumbmitted, send the prompt to openai to rob ~0.35$ from the user
      if submit_button:
      st.session_state.display_commercial_analysis = False
        st.session_state.api_response = False
        if not api_key:
        st.error("Please enter an API key.")
        else:
            # get the response
            
            # progress_bar = st.progress(0)
            
            with st.spinner('Evaluating your idea, please wait for aproximately 40 seconds...'):
    
                # for i in range(100):
                #     progress_bar.progress(i+1)
                #     time.sleep(1)
                    
                try:
                    st.session_state.api_response = evaluate_idea(problem, solution)
                    # api_response = evaluate_idea(problem, solution)
            #    except openai.error.InvalidRequestError as e:
            #        if e.status_code == 401:  # Unauthorized, typically due to invalid API key
            #            st.error("Invalid API key. Please check your API key and try again.")
            #        else:
                        st.error(f"An error occurred: {e}")
            #    else:
                    # This 'else' block runs only if no exception was raised
                    if not st.session_state.api_response:
                        # Display warning message if API call fails to retrieve data
                        st.error("Unable to retrieve data. Please try again later.")

                           
    # if api_response:
    if st.session_state.api_response:
        api_response = st.session_state.api_response
        temp_response = api_response
        # Display if the idea is sustainability related with highlighting
        is_sustainable = api_response['Idea_Sustainability_Related'] == True
        
        sustainability_comment = api_response['Idea_Sustainability_Related_Comment']
        # st.markdown(f"<h3 style='color:blue;'>Is the Idea Sustainability Related? {'Yes' if is_sustainable else 'No'}</h3>", unsafe_allow_html=True)
        if is_sustainable:
            st.markdown("<h3 style='color: green;'>We've evaluated this, and it's exciting news: This idea is sustainability-related!</h3>", unsafe_allow_html=True)
        else:
            st.markdown("<h3 style='color: red;'>After careful evaluation, it appears that this idea is not sustainability-related.</h3>", unsafe_allow_html=True)

        # st.write("### Sustainability Analysis:")
        st.write(sustainability_comment)

        # if the idea is not sustainable, proceed with displaying the scores.
        if is_sustainable:
            scores = [int(api_response['Evaluation']['SDG_Scores'][metric]['Score']) for metric in metrics]
            comments = [api_response['Evaluation']['SDG_Scores'][metric]['Comment'] for metric in metrics]
            total_score = int(api_response['Evaluation']['Total_Score'])  # Convert to integer
            analysis_context = api_response['Evaluation']['Summary']
            novelty_score = int(api_response['Evaluation']['Novelty_Score'])  # Convert to integer
            novelty_comment = api_response['Evaluation']['Novelty_Evaluation']['Comment']
            
            
            # Displaying novelty score and analysis with highlighting
            st.markdown(f"<h3 style='color:purple;'>Novelty Score: {novelty_score} / 100</h3>", unsafe_allow_html=True)
            st.write("### Novelty Analysis:")
            st.write(novelty_comment)

            
            # get tfidf novelty score with user-provided problem and solution
            max_similarity, tfidf_is_novelty = get_tfidf_novelty(problem, solution)
            
            # Check if the response is novelty or not
            novelty_status = "Yes" if tfidf_is_novelty else "No"
            
            # Display the novelty similarity score with decimals and novelty status
            st.markdown(f"<h3 style='color:orange;'>Similarity Score: {max_similarity:.2f} / 1</h3>", unsafe_allow_html=True)
            # st.markdown(f"<h3 style='color:orange;'>Is it Novelty? {novelty_status}</h3>", unsafe_allow_html=True)

            with st.expander("Understanding the Novelty Similarity Score"):
                st.write("""
                    - The Novelty Similarity Score indicates the degree of similarity between your idea and existing ideas within the AI EarthHack Dataset.
                    - A higher score suggests that your idea is more closely related to concepts already present in the dataset.
                    - Conversely, a lower score suggests that your idea is unique or novel in the context of this dataset.
                    - Ideas with a score below a certain threshold are considered novel, highlighting their uniqueness compared to the dataset. This serves as a complementary assessment alongside the GPT-4-Turbo engine's analysis.
                """)

            # Display the summary score without decimals
            st.markdown(f"<h3 style='color:green;'>Sustainability Score: {total_score} / 170</h3>", unsafe_allow_html=True)
            st.write("### Sustainability Analysis:")
            st.write(analysis_context)

            
            # Modify DataFrame to include comments
            score_df = pd.DataFrame({
                'Metric': formatted_metrics,
                'Score': scores,
                'Comment': comments,
                'Level': [score_to_emoji(score) for score in scores]
            })

            # col1, col2 = st.columns(2)  # Creates two columns
            
            # Radar chart
            # with col1: 
            st.write("### Radar Chart Evaluation Results:")
            num_vars = len(formatted_metrics)
            angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
            angles += angles[:1]  # Complete the loop

            # Use 'scores' directly as it is already a list
            scores_list = scores + scores[:1]  # Repeat the first score to close the radar chart

            fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
            ax.fill(angles, scores_list, color='green', alpha=0.25)
            ax.plot(angles, scores_list, color='green', linewidth=2)
            ax.set_yticklabels([])
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(formatted_metrics)
        
            st.pyplot(fig)

            # with col2:
            # Seaborn barplot
            
            st.write("### Bar Chart Evaluation Results:")
            plt.figure(figsize=(10, 6))
            # n_colors = score_df['Score'].nunique()
            # palette = sns.color_palette("flare", n_colors=n_colors)
            palette = sns.color_palette("husl", 9)
            green_color = sns.color_palette("Greens", 6)[-2]  # A shade of green

            # sns.barplot(x='Score', y='Metric', data=score_df, color=green_color)

            sns.barplot(x='Score', y='Metric', data=score_df, palette=palette)
            plt.xlabel('Score out of 10')
            st.set_option('deprecation.showPyplotGlobalUse', False)
            st.pyplot()

            
            # Displaying scores as a styled table using markdown
            st.markdown("### Evaluation Table")
            st.markdown(
                score_df.to_html(index=False, escape=False, justify='center', classes='table'),
                unsafe_allow_html=True
            )
        
            # Apply custom CSS for table styling
            st.markdown("""
                <style>
                    .table {width: 100%; margin-left: auto; margin-right: auto; border-collapse: collapse;}
                    .table td, .table th {border: none;}
                    th {text-align: center; font-size: 18px; font-weight: bold;}
                    td {text-align: center;}
                </style>
                """, unsafe_allow_html=True)


    # else:
    #     # Display warning message if API call fails
    #     st.error("Unable to retrieve data. Please try again later.")
            
        # Display a section for commercial analysis
            st.markdown("---")
            st.markdown("### **Do you want further economical analysis?üí∏**")
            # st.markdown("*Note: This will incur additional costs with the use of the API key.*")
        
            # Button for commercial analysis
            commercial_analysis_button = st.button("Display Economical Analysis")
        
            # Mock commercial analysis process (commented out, use for real implementation)
            if commercial_analysis_button:
                st.session_state.display_commercial_analysis = True            
        
            if st.session_state.display_commercial_analysis:
                with st.spinner('Processing economical analysis, please wait...'):
          
                    
                    top_5_similar_docs, avg_num_competitors, avg_total_raised = get_top_5_tfidf(problem, solution)
                    df_cat = get_business_status_distribution(top_5_similar_docs)
                
                    category_summary = df_cat.groupby('Category')['Percentage'].sum()
                
                    # Find the category with the highest total percentage
                    most_likely_category = category_summary.idxmax()
                    
                    # Group by 'BusinessStatus' and sum the 'Percentage'
                    business_status_summary = df_cat.groupby('BusinessStatus')['Percentage'].sum()
                    
                    # Find the business status with the highest total percentage
                    most_likely_business_status = business_status_summary.idxmax()
                    
                    # Find the number of competitor percentile
                    NumCompetitors_percentile = round(get_percentile_by_category(documents, 'NumCompetitors',avg_num_competitors,most_likely_category),2)
                    
                    # Find the totalraised percentile
                    TotalRaised_percentile = round(get_percentile_by_category(documents, 'TotalRaised',avg_total_raised,most_likely_category),2)
                
                    output = generate_commercial_analysis(NumCompetitors_percentile, most_likely_category, most_likely_business_status, TotalRaised_percentile, avg_num_competitors, avg_total_raised)
                            
                
                    st.write('<br><br>', unsafe_allow_html=True)
                    col1, col2 = st.columns(2)
                
                    with col1:
                        st.metric(label="##### ‚öîÔ∏èEstimated Number of Competitors", value=avg_num_competitors)
                    
                    with col2:
                        st.metric(label="##### üìàEstimated Investments (mln)", value=f"${avg_total_raised:,}")
                
                    st.write('<br><br>', unsafe_allow_html=True)
                
                
                    ## DONUTS
                    # Combine all data into a single pie chart
                    plt.figure(figsize=(10, 6))
                    
                    # Plot each entry in the DataFrame as a separate slice in the pie chart
                    wedges, texts, autotexts = plt.pie(df_cat['Percentage'], labels=df_cat['BusinessStatus'], autopct='%1.1f%%', startangle=140)
                    
                    # Draw a circle at the center of pie to turn it into a donut chart
                    centre_circle = plt.Circle((0,0),0.70,fc='white')
                    fig = plt.gcf()
                    fig.gca().add_artist(centre_circle)
                    
                    legend_labels = [f"{category}" for category in df_cat['Category']]
                    plt.legend(wedges, legend_labels, title="Categories", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
                    
                    plt.title('Combined Business Status Distribution')
                    st.pyplot(plt)    
                
                    # st.write(output)
                
                    # output = generate_commercial_analysis(NumCompetitors_percentile, most_likely_category, most_likely_business_status, TotalRaised_percentile, avg_num_competitors, avg_total_raised)
                    st.markdown("### Economical Analysis")
                    st.write("##### *üéâCongratulations on developing your innovative idea! After a thorough comparison with our extensive industry database, we've gathered insightful findings for your venture:*")
                    # Split the output into key points
                    key_points = output.split("\n\n")
                    
                    # Display each key point as a bullet point
                
                    st.markdown("<ul>", unsafe_allow_html=True)
                    for point in key_points:
                        st.markdown(f"<li style='font-size: 18px;'>{point}</li>", unsafe_allow_html=True)
        
                    st.markdown("</ul>", unsafe_allow_html=True)
        
                    st.write("##### *Wishing you the best in your entrepreneurial journey. Your innovation has the potential to make a remarkable difference!*")
        
                # progress_bar.empty()

        # if st.session_state.api_response:
            # csv_data = convert_data_to_csv(st.session_state.api_response)
            st.download_button(
                label="Download Analysis",
                data=json.dumps(api_response),
                file_name='Analysis.json'
                # mime='text/csv'
            )    

# Add a key in session state to store commercial analysis data
if 'commercial_analysis_results' not in st.session_state:
    st.session_state.commercial_analysis_results = {}
    
elif input_method == 'Upload CSV':

    # st.session_state.uploaded_file = False

    with st.expander("CSV Upload Instructions", expanded=True):
        st.write("""
            Please follow these guidelines for your CSV file:
            - Your CSV file should contain only two columns: 'problem' and 'solution'.
            - Ensure the column titles are exactly 'problem' and 'solution'. The column names are case sensitive.
            - If your file has headers, they should match the above column names exactly.
            - The file should be encoded in UTF-8 or ISO-8859-1.
            - Each row in the file should represent a separate problem-solution pair.
        """)
    
    uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

    if uploaded_file is not None:

        try:
            # Try reading with default encoding (UTF-8)
            df = pd.read_csv(uploaded_file)
        except UnicodeDecodeError:
            # If UnicodeDecodeError, try reading with alternative encoding
            uploaded_file.seek(0)  # Reset file pointer to the beginning
            df = pd.read_csv(uploaded_file, encoding='ISO-8859-1')

        # Convert column names to lowercase
        df.columns = [col.lower() for col in df.columns]

        # Check if 'id' column exists, if not add it
        if 'id' not in df.columns:
            df.insert(0, 'id', range(1, 1 + len(df)))

        # Check for necessary columns 'problem' and 'solution'
        if 'problem' in df.columns and 'solution' in df.columns:

            if not api_key:
                st.error("Please enter an API key.")
            else:
                # Display the DataFrame
                # st.write("Uploaded Data:")
                # st.dataframe(df)

                # This line is for not reprocess every time
                # if 'my_dataframe' not in st.session_state.keys():
                with st.spinner('Evaluating your ideas, please wait for aproximately 90 seconds...'):
                    processed_results = process_inputs_in_parallel(df, api_key)
                    final_df = processed_results_to_df(processed_results)
                    st.session_state['my_dataframe'] = final_df.copy()
                # st.dataframe(final_df)

                # Store final_df in session state for later use
                # st.session_state.final_df = final_df
    
                # Find the indices of the highest total_score and novelty_score
                highest_total_score_idx = st.session_state['my_dataframe']['total_score'].idxmax()
                highest_novelty_score_idx = st.session_state['my_dataframe']['novelty_score'].idxmax()
                
                num_ideas = len(st.session_state['my_dataframe'])
                summary_sentence = f"We have evaluated {num_ideas} of your ideas. Idea {highest_total_score_idx + 1} achieved the overall best score, while Idea {highest_novelty_score_idx + 1} has the highest novelty score."
                st.markdown(f"##### {summary_sentence}")
                
                # Iterate through each row in final_df to display the results
                for index, row in st.session_state['my_dataframe'].iterrows():
                    # Determine if the expander should be open by default
                    if index == highest_total_score_idx:
                        expanded = True
                        special_message = "Congratulations! üéâ This idea has achieved the overall best score in our evaluation."
                    elif index == highest_novelty_score_idx:
                        expanded = True
                        special_message = "Congratulations! üåü This idea has the highest novelty score, showcasing its unique and innovative aspects."
                    else:
                        expanded = False
                        special_message = ""
    
                    # problem_snippet = row['problem'][:50] + "..."  # Display first 50 characters of the problem
                    if isinstance(row['problem'], str):
                        problem_snippet = row['problem'][:50] + "..."  # Display first 50 characters of the problem
                    else:
                        problem_snippet = "No problem description available"
                    expander_label = f"üìù Idea {index+1}: {problem_snippet}"

                    is_sustainable = row['is_sustainable']
                    total_score = row['total_score']
                    novelty_score = row['novelty_score']
                    novelty_comment = row['novelty_comment']
                    
                    with st.expander(expander_label, expanded=expanded):
                        if special_message:
                            st.markdown(f"##### **{special_message}**")
                                
                        st.markdown(f"**Problem:** {row['problem']}")
                        st.markdown(f"**Solution:** {row['solution']}")
                

    
                        # Sustainability Related
                        # is_sustainable = row['is_sustainable']
                        
                        # sustainability_status = "Yes" if is_sustainable else "No"
                        # st.markdown(f"<h3 style='color:blue;'>Is the Idea Sustainability Related? {sustainability_status}</h3>", unsafe_allow_html=True)
                        if is_sustainable:
                            st.markdown("<h3 style='color: green;'>We've evaluated this, and it's exciting news: This idea is sustainability-related!</h3>", unsafe_allow_html=True)
                        else:
                            st.markdown("<h3 style='color: red;'>After careful evaluation, it appears that this idea is not sustainability-related.</h3>", unsafe_allow_html=True)

                        # Only display scores and novelty analysis if the idea is not 'bad'
                        if not pd.isna(total_score) and not pd.isna(novelty_score):
                            st.markdown(f"<h3 style='color:green;'>Summary Score: {total_score} / 170</h3>", unsafe_allow_html=True)
                            st.markdown(f"<h3 style='color:purple;'>Novelty Score: {novelty_score} / 100</h3>", unsafe_allow_html=True)
                            st.write("### Novelty Analysis:")
                            st.write(novelty_comment)
                            
                        # # Total Score
                        # st.markdown(f"<h3 style='color:green;'>Sustainability Score: {row['total_score']} / 170</h3>", unsafe_allow_html=True)
    
                        # # Novelty Score and Analysis
                        # st.markdown(f"<h3 style='color:purple;'>Novelty Score: {row['novelty_score']} / 170</h3>", unsafe_allow_html=True)
                        # st.write("### Novelty Analysis:")
                        # st.write(row['novelty_comment'])

                        
                        # Generate a unique key for each problem-solution pair
                        # commercial_key = f"commercial_{index}"
                        
                        # button_key = f"button_{index}"

                # st.markdown("---")
                # st.markdown("### **Do you want further economical analysis?üí∏**")
            
                # # Dropdown for selecting an idea
                # idea_options = [f"üìù Idea {index+1}: {row['problem'][:50]}..." for index, row in final_df.iterrows()]
                # selected_idea_format = st.selectbox("Select an idea for economical analysis:", idea_options, format_func=lambda x: x)


                # if st.button("Perform Economical Analysis"):
                #     selected_index = int(selected_idea.split(' ')[1]) - 1
                    
                #     if st.session_state.selected_idea_index != selected_index:
                #         st.session_state.selected_idea_index = selected_index
                #         problem = final_df.iloc[selected_index]['problem']
                #         solution = final_df.iloc[selected_index]['solution']
                            
                #         with st.spinner('Processing economical analysis, please wait...'):
            
                #             # commercial_analysis_result = perform_commercial_analysis(problem, solution, documents)
    
                #             top_5_similar_docs, avg_num_competitors, avg_total_raised = get_top_5_tfidf(problem, solution)
                #             df_cat = get_business_status_distribution(top_5_similar_docs)
    
                #             category_summary = df_cat.groupby('Category')['Percentage'].sum()
                        
                #             # Find the category with the highest total percentage
                #             most_likely_category = category_summary.idxmax()
                            
                #             # Group by 'BusinessStatus' and sum the 'Percentage'
                #             business_status_summary = df_cat.groupby('BusinessStatus')['Percentage'].sum()
                            
                #             # Find the business status with the highest total percentage
                #             most_likely_business_status = business_status_summary.idxmax()
                            
                #             # Find the number of competitor percentile
                #             NumCompetitors_percentile = round(get_percentile_by_category(documents, 'NumCompetitors',avg_num_competitors,most_likely_category),2)
                            
                #             # Find the totalraised percentile
                #             TotalRaised_percentile = round(get_percentile_by_category(documents, 'TotalRaised',avg_total_raised,most_likely_category),2)
                        
                #             output = generate_commercial_analysis(NumCompetitors_percentile, most_likely_category, most_likely_business_status, TotalRaised_percentile, avg_num_competitors, avg_total_raised)
                              
                #             # Store the result and other details in session state
                #             # st.session_state.commercial_analysis_results[commercial_key] = {
                #             #     "output": output,
                #             #     "avg_num_competitors": avg_num_competitors,
                #             #     "avg_total_raised": avg_total_raised,
                #             #     "df_cat": df_cat
                #             # }
    
    
                #         # if commercial_key in st.session_state.commercial_analysis_results:                           
                            
                #             # with st.spinner('Processing commercial analysis, please wait...'):
                #             # analysis_data = st.session_state.commercial_analysis_results[commercial_key]
            
                            
                #             st.write('<br><br>', unsafe_allow_html=True)
                #             col1, col2 = st.columns(2)
                        
                #             with col1:
                #                 st.metric(label="##### ‚öîÔ∏èEstimated Number of Competitors", value=avg_num_competitors)
                            
                #             with col2:
                #                 st.metric(label="##### üìàEstimated Investments (mln)", value=f"${avg_total_raised:,}")
                        
                #             st.write('<br><br>', unsafe_allow_html=True)
                            
                        
                #             ## DONUTS
                #             # Combine all data into a single pie chart
                #             plt.figure(figsize=(10, 6))
                            
                #             # Plot each entry in the DataFrame as a separate slice in the pie chart
                #             wedges, texts, autotexts = plt.pie(df_cat['Percentage'], labels=df_cat['BusinessStatus'], autopct='%1.1f%%', startangle=140)
                            
                #             # Draw a circle at the center of pie to turn it into a donut chart
                #             centre_circle = plt.Circle((0,0),0.70,fc='white')
                #             fig = plt.gcf()
                #             fig.gca().add_artist(centre_circle)
                            
                #             legend_labels = [f"{category}" for category in df_cat['Category']]
                #             plt.legend(wedges, legend_labels, title="Categories", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
                            
                #             plt.title('Combined Business Status Distribution')
                #             st.pyplot(plt)    
                        
                #             # st.write(output)
                        
                #             # output = generate_commercial_analysis(NumCompetitors_percentile, most_likely_category, most_likely_business_status, TotalRaised_percentile, avg_num_competitors, avg_total_raised)
                #             st.markdown("### Economical Analysis")
                #             st.write("##### *üéâCongratulations on developing your innovative idea! After a thorough comparison with our extensive industry database, we've gathered insightful findings for your venture:*")
                #             # Split the output into key points
                #             key_points = output.split("\n\n")
                            
                #             # Display each key point as a bullet point
                        
                #             st.markdown("<ul>", unsafe_allow_html=True)
                #             for point in key_points:
                #                 st.markdown(f"<li style='font-size: 18px;'>{point}</li>", unsafe_allow_html=True)
                
                #             st.markdown("</ul>", unsafe_allow_html=True)
                
                #             st.write("##### *Wishing you the best in your entrepreneurial journey. Your innovation has the potential to make a remarkable difference!*")


                #######
                # Download function, would cause unable to read another csv, so we deleted this function.
                # st.download_button(
                #     label="Download Analysis",
                #     data=convert_df_to_csv(st.session_state['my_dataframe']),
                #     file_name='csv_analysis.csv',
                #     # mime='text/csv'
                # )    

        else:
            st.error("The CSV file must contain 'problem' and 'solution' columns.")



        
        
        


